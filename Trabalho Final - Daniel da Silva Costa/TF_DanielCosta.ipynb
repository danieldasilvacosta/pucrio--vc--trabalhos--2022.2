{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yukxIi6LniSQ",
        "outputId": "f74f7039-ba02-4f3c-ee4d-93c93a8aea23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "995UeTpNnpqJ",
        "outputId": "f05a2969-4c37-4aff-b813-b73ec1eb0645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.2] [PUC-Rio] Visão Computacional - Professor: Marcelo Gattass/Trabalhos/Trabalho Final/Code/What does a CNN see?\n"
          ]
        }
      ],
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.2] [PUC-Rio] Visão Computacional - Professor: Marcelo Gattass/Trabalhos/Trabalho Final/Code/What does a CNN see?/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cg29tq9_nx3_",
        "outputId": "ecf68ee1-f7d3-4ffe-97ca-f868712b6450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.2] [PUC-Rio] Visão Computacional - Professor: Marcelo Gattass/Trabalhos/Trabalho Final/Code/What does a CNN see?\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fmp5VkmDnzJ6"
      },
      "outputs": [],
      "source": [
        "data_folder = './data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r49vJQx6m_n5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import h5py\n",
        "import shutil\n",
        "import imgaug as aug\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import imgaug.augmenters as iaa\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from pathlib import Path\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, InputLayer, Flatten\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution() # daniel\n",
        "\n",
        "\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format=\"svg\"\n",
        "\n",
        "# Daniel\n",
        "from tensorflow.keras import datasets, layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "O63jTZkRm_n8"
      },
      "outputs": [],
      "source": [
        "# Set the seed for hash based operations in python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "seed=1234\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "# tf.set_random_seed(seed) # obsolete\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Make the augmentation sequence deterministic\n",
        "aug.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GDVCZ3Som_n-"
      },
      "outputs": [],
      "source": [
        "# As usual, define some paths first to make life simpler\n",
        "training_data = Path(data_folder + '/training/') \n",
        "validation_data = Path(data_folder + '/validation/') \n",
        "labels_path = Path(data_folder + '/monkey_labels.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pFmq_UfRm_oA",
        "outputId": "c708dc42-ad54-41d4-97b6-5cb7d60dcd14"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Label             Latin Name                Common Name  Train Images  \\\n",
              "0    n0      alouatta_palliata             mantled_howler           131   \n",
              "1    n1     erythrocebus_patas               patas_monkey           139   \n",
              "2    n2         cacajao_calvus                bald_uakari           137   \n",
              "3    n3         macaca_fuscata           japanese_macaque           152   \n",
              "4    n4        cebuella_pygmea             pygmy_marmoset           131   \n",
              "5    n5        cebus_capucinus      white_headed_capuchin           141   \n",
              "6    n6        mico_argentatus           silvery_marmoset           132   \n",
              "7    n7       saimiri_sciureus     common_squirrel_monkey           142   \n",
              "8    n8        aotus_nigriceps  black_headed_night_monkey           133   \n",
              "9    n9  trachypithecus_johnii             nilgiri_langur           132   \n",
              "\n",
              "   Validation Images  \n",
              "0                 26  \n",
              "1                 28  \n",
              "2                 27  \n",
              "3                 30  \n",
              "4                 26  \n",
              "5                 28  \n",
              "6                 26  \n",
              "7                 28  \n",
              "8                 27  \n",
              "9                 26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-899440d6-3ba4-4936-9767-10ff759ae49d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Latin Name</th>\n",
              "      <th>Common Name</th>\n",
              "      <th>Train Images</th>\n",
              "      <th>Validation Images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n0</td>\n",
              "      <td>alouatta_palliata</td>\n",
              "      <td>mantled_howler</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n1</td>\n",
              "      <td>erythrocebus_patas</td>\n",
              "      <td>patas_monkey</td>\n",
              "      <td>139</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n2</td>\n",
              "      <td>cacajao_calvus</td>\n",
              "      <td>bald_uakari</td>\n",
              "      <td>137</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>n3</td>\n",
              "      <td>macaca_fuscata</td>\n",
              "      <td>japanese_macaque</td>\n",
              "      <td>152</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n4</td>\n",
              "      <td>cebuella_pygmea</td>\n",
              "      <td>pygmy_marmoset</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>n5</td>\n",
              "      <td>cebus_capucinus</td>\n",
              "      <td>white_headed_capuchin</td>\n",
              "      <td>141</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>n6</td>\n",
              "      <td>mico_argentatus</td>\n",
              "      <td>silvery_marmoset</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>n7</td>\n",
              "      <td>saimiri_sciureus</td>\n",
              "      <td>common_squirrel_monkey</td>\n",
              "      <td>142</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>n8</td>\n",
              "      <td>aotus_nigriceps</td>\n",
              "      <td>black_headed_night_monkey</td>\n",
              "      <td>133</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>n9</td>\n",
              "      <td>trachypithecus_johnii</td>\n",
              "      <td>nilgiri_langur</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-899440d6-3ba4-4936-9767-10ff759ae49d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-899440d6-3ba4-4936-9767-10ff759ae49d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-899440d6-3ba4-4936-9767-10ff759ae49d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "labels_info = []\n",
        "\n",
        "# Read the file\n",
        "lines = labels_path.read_text().strip().splitlines()[1:]\n",
        "for line in lines:\n",
        "    line = line.split(',')\n",
        "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
        "    line[3], line[4] = int(line[3]), int(line[4])\n",
        "    line = tuple(line)\n",
        "    labels_info.append(line)\n",
        "    \n",
        "# Convert the data into a pandas dataframe\n",
        "labels_info = pd.DataFrame(labels_info, columns=['Label', 'Latin Name', 'Common Name', \n",
        "                                                 'Train Images', 'Validation Images'], index=None)\n",
        "# Sneak peek \n",
        "labels_info.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHuT1Hz8m_oB",
        "outputId": "9763eb65-2fa8-470e-f272-4638a4556a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'mantled_howler', 1: 'patas_monkey', 2: 'bald_uakari', 3: 'japanese_macaque', 4: 'pygmy_marmoset', 5: 'white_headed_capuchin', 6: 'silvery_marmoset', 7: 'common_squirrel_monkey', 8: 'black_headed_night_monkey', 9: 'nilgiri_langur'}\n"
          ]
        }
      ],
      "source": [
        "# Create a dictionary to map the labels to integers\n",
        "labels_dict= {'n0':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'n5':5, 'n6':6, 'n7':7, 'n8':8, 'n9':9}\n",
        "\n",
        "# map labels to common names\n",
        "names_dict = dict(zip(labels_dict.values(), labels_info[\"Common Name\"]))\n",
        "print(names_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_MLw2_dm_oC",
        "outputId": "c374c039-f29d-4576-a24f-c3daaa2cc46e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of traininng samples:  1096\n",
            "Number of validation samples:  272\n",
            "\n",
            "                         image  label\n",
            "0  data/training/n2/n2117.jpg      2\n",
            "1  data/training/n7/n7028.jpg      7\n",
            "2  data/training/n0/n0155.jpg      0\n",
            "3  data/training/n7/n7064.jpg      7\n",
            "4  data/training/n2/n2133.jpg      2 \n",
            "\n",
            "=================================================================\n",
            "\n",
            "\n",
            "                           image  label\n",
            "0   data/validation/n7/n718.jpg      7\n",
            "1  data/validation/n6/n6013.jpg      6\n",
            "2  data/validation/n7/n7012.jpg      7\n",
            "3   data/validation/n5/n512.jpg      5\n",
            "4   data/validation/n5/n509.jpg      5\n"
          ]
        }
      ],
      "source": [
        "# Creating a dataframe for the training dataset\n",
        "train_df = []\n",
        "for folder in os.listdir(training_data):\n",
        "    # Define the path to the images\n",
        "    imgs_path = training_data / folder\n",
        "    \n",
        "    # Get the list of all the images stored in that directory\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    \n",
        "    # Store each image path and corresponding label \n",
        "    for img_name in imgs:\n",
        "        train_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# Creating dataframe for validation data in a similar fashion\n",
        "valid_df = []\n",
        "for folder in os.listdir(validation_data):\n",
        "    imgs_path = validation_data / folder\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    for img_name in imgs:\n",
        "        valid_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "        \n",
        "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# How many samples do we have in our training and validation data?\n",
        "print(\"Number of traininng samples: \", len(train_df))\n",
        "print(\"Number of validation samples: \", len(valid_df))\n",
        "\n",
        "# sneak peek of the training and validation dataframes\n",
        "print(\"\\n\",train_df.head(), \"\\n\")\n",
        "print(\"=================================================================\\n\")\n",
        "print(\"\\n\", valid_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4zcekSk9m_oD"
      },
      "outputs": [],
      "source": [
        "# some constants(not truly though!) \n",
        "\n",
        "# dimensions to consider for the images\n",
        "img_rows, img_cols, img_channels = 224,224,3\n",
        "\n",
        "# batch size for training  \n",
        "batch_size=8\n",
        "\n",
        "# total number of classes in the dataset\n",
        "nb_classes=10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XSt-OHwym_oD"
      },
      "outputs": [],
      "source": [
        "# Augmentation sequence \n",
        "seq = iaa.OneOf([\n",
        "    iaa.Fliplr(), # horizontal flips\n",
        "    iaa.Affine(rotate=20), # roatation\n",
        "    iaa.Multiply((1.2, 1.5))]) #random brightness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4hASMeAOm_oE"
      },
      "outputs": [],
      "source": [
        "def data_generator(data, batch_size, is_validation_data=False):\n",
        "    # Get total number of samples in the data\n",
        "    n = len(data)\n",
        "    nb_batches = int(np.ceil(n/batch_size))\n",
        "\n",
        "    # Get a numpy array of all the indices of the input data\n",
        "    indices = np.arange(n)\n",
        "    \n",
        "    # Define two numpy arrays for containing batch data and labels\n",
        "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
        "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
        "    \n",
        "    while True:\n",
        "        if not is_validation_data:\n",
        "            # shuffle indices for the training data\n",
        "            np.random.shuffle(indices)\n",
        "            \n",
        "        for i in range(nb_batches):\n",
        "            # get the next batch \n",
        "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
        "            \n",
        "            # process the next batch\n",
        "            for j, idx in enumerate(next_batch_indices):\n",
        "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                label = data.iloc[idx][\"label\"]\n",
        "                \n",
        "                if not is_validation_data:\n",
        "                    img = seq.augment_image(img)\n",
        "                \n",
        "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
        "                batch_data[j] = img\n",
        "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
        "            \n",
        "            batch_data = preprocess_input(batch_data)\n",
        "            yield batch_data, batch_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "gJ8LEwAJm_oF"
      },
      "outputs": [],
      "source": [
        "#training data generator \n",
        "train_data_gen = data_generator(train_df, batch_size)\n",
        "\n",
        "# validation data generator \n",
        "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cpRZS2Wtm_oH"
      },
      "outputs": [],
      "source": [
        "# simple function that returns the base model\n",
        "def get_base_model():\n",
        "    base_model = VGG16(input_shape=(img_rows, img_cols, img_channels), weights='imagenet', include_top=True)\n",
        "    return base_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Daniel's Model"
      ],
      "metadata": {
        "id": "4DYjWiHEbeLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "# tf.keras.layers.Conv2D( filters, kernel_size, ...)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.InputLayer( input_shape=(224, 224, 3) )\n",
        "])\n",
        "\n",
        "model.add( layers.Conv2D(64, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(64, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(128, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(128, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(256, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(256, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(256, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(512, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(512, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(512, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(512, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(512, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.Conv2D(512, (4, 4), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Flatten() )\n",
        "model.add( layers.Dense(4096, activation='relu') )\n",
        "model.add( layers.Dense(4096, activation='relu') )\n",
        "model.add( layers.Dropout(0.3) )\n",
        "model.add( layers.Dense(10, activation='softmax') )\n",
        "\n",
        "# To correct some bug on input\n",
        "model = Model(model.input, model.output)\n",
        "\n",
        "optimizer = RMSprop(0.001)\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwBknUFEbd5U",
        "outputId": "a63108e2-12de-4040-f073-a99f7ab641c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 224, 224, 64)      3136      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 64)      65600     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 128)     131200    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 128)     262272    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 56, 56, 256)       524544    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 256)       1048832   \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 256)       1048832   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 28, 28, 512)       2097664   \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       4194816   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       4194816   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 512)       4194816   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 14, 14, 512)       4194816   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 14, 14, 512)       4194816   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              102764544 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                40970     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 145,742,986\n",
            "Trainable params: 145,742,986\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AxTpbjyjm_oI"
      },
      "outputs": [],
      "source": [
        "# always user earlystopping\n",
        "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "# checkpoint to save model\n",
        "chkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n",
        "\n",
        "# number of training and validation steps for training and validation\n",
        "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
        "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mYCzLnpI8ZaC"
      },
      "outputs": [],
      "source": [
        "# nb_epochs=100\n",
        "nb_epochs=5 # daniel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "G5c29rBSm_oI",
        "outputId": "03e51cf5-547a-42a1-c08c-d4b9f3cbe425"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "129/137 [===========================>..] - ETA: 23s - batch: 64.0000 - size: 8.0000 - loss: 41802801.4410 - accuracy: 0.1163"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m     return func.fit(\n\u001b[0m\u001b[1;32m    777\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    568\u001b[0m     training_utils_v1.check_generator_arguments(\n\u001b[1;32m    569\u001b[0m         y, sample_weight, validation_split=validation_split)\n\u001b[0;32m--> 570\u001b[0;31m     return fit_generator(\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1073\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4282\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4284\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   4285\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   4286\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m                                                run_metadata_ptr)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# train the model \n",
        "history1 = model.fit(train_data_gen, \n",
        "                              epochs=nb_epochs, \n",
        "                              steps_per_epoch=nb_train_steps, \n",
        "                              validation_data=valid_data_gen, \n",
        "                              validation_steps=nb_valid_steps,\n",
        "                              callbacks=[es,chkpt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Qhkb7xSA6m5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "89a62a37-a8a8-407d-dc32-f6bb2aab2876"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6ce60dd3fd4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history1' is not defined"
          ]
        }
      ],
      "source": [
        "history1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-IB0o62m_oJ"
      },
      "outputs": [],
      "source": [
        "# let's plot the loss and accuracy \n",
        "\n",
        "# get the training and validation accuracy from the history object\n",
        "train_acc = history1.history['accuracy']\n",
        "valid_acc = history1.history['val_accuracy']\n",
        "\n",
        "# get the loss\n",
        "train_loss = history1.history['loss']\n",
        "valid_loss = history1.history['val_loss']\n",
        "\n",
        "# get the number of entries\n",
        "xvalues = np.arange(len(train_acc))\n",
        "\n",
        "# visualize\n",
        "f,ax = plt.subplots(1,2, figsize=(10,5))\n",
        "ax[0].plot(xvalues, train_loss)\n",
        "ax[0].plot(xvalues, valid_loss)\n",
        "ax[0].set_title(\"Loss curve\")\n",
        "ax[0].set_xlabel(\"Epoch\")\n",
        "ax[0].set_ylabel(\"loss\")\n",
        "ax[0].legend(['train', 'validation'])\n",
        "\n",
        "ax[1].plot(xvalues, train_acc)\n",
        "ax[1].plot(xvalues, valid_acc)\n",
        "ax[1].set_title(\"Accuracy\")\n",
        "ax[1].set_xlabel(\"Epoch\")\n",
        "ax[1].set_ylabel(\"accuracy\")\n",
        "ax[1].legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbyCEgjOm_oJ"
      },
      "outputs": [],
      "source": [
        "# What is the final loss and accuracy on our validation data?\n",
        "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
        "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtftPiu_m_oK"
      },
      "outputs": [],
      "source": [
        "outputs = [layer.output for layer in model.layers[1:18]]\n",
        "\n",
        "vis_model = Model(model.input, outputs)\n",
        "\n",
        "for layer in vis_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "vis_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBwGla4tm_oK"
      },
      "outputs": [],
      "source": [
        "# store the layer names we are interested in\n",
        "layer_names = []\n",
        "for layer in outputs:\n",
        "    layer_names.append(layer.name.split(\"/\")[0])\n",
        "\n",
        "    \n",
        "print(\"Layers going to be used for visualization: \")\n",
        "print(layer_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( f'layer_names [before]: {layer_names}' )\n",
        "\n",
        "layer_names_temp = layer_names\n",
        "layer_names = list()\n",
        "for layer in layer_names_temp:\n",
        "\n",
        "  if 'conv' in layer:\n",
        "    # print(layer)\n",
        "    layer_names.append( layer )\n",
        "\n",
        "print( '=========================================' )\n",
        "print( f'layer_names [after]: {layer_names}' )"
      ],
      "metadata": {
        "id": "N71NRlVBrVkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTk3zuOem_oL"
      },
      "outputs": [],
      "source": [
        "def get_CAM(processed_image, predicted_label):\n",
        "    \"\"\"\n",
        "    This function is used to generate a heatmap for a sample image prediction.\n",
        "    \n",
        "    Args:\n",
        "        processed_image: any sample image that has been pre-processed using the \n",
        "                       `preprocess_input()`method of a keras model\n",
        "        predicted_label: label that has been predicted by the network for this image\n",
        "    \n",
        "    Returns:\n",
        "        heatmap: heatmap generated over the last convolution layer output \n",
        "    \"\"\"\n",
        "    # we want the activations for the predicted label\n",
        "    predicted_output = model.output[:, predicted_label]\n",
        "    \n",
        "    # choose the last conv layer in your model\n",
        "    # last_conv_layer = model.get_layer('block5_conv3')\n",
        "    last_conv_layer = model.get_layer(layer_names[-1])\n",
        "    \n",
        "    # get the gradients wrt to the last conv layer\n",
        "    grads = K.gradients(predicted_output, last_conv_layer.output)[0]\n",
        "    \n",
        "    # take mean gradient per feature map\n",
        "    grads = K.mean(grads, axis=(0,1,2)) # GAP - Global Average Pooling\n",
        "    \n",
        "    # Define a function that generates the values for the output and gradients\n",
        "    evaluation_function = K.function([model.input], [grads, last_conv_layer.output[0]])\n",
        "    \n",
        "    # get the values\n",
        "    grads_values, conv_ouput_values = evaluation_function([processed_image])\n",
        "    \n",
        "    # CAM - Class Activation Map\n",
        "    # iterate over each feature map in yout conv output and multiply\n",
        "    # the gradient values with the conv output values. This gives an \n",
        "    # indication of \"how important a feature is\"\n",
        "    # for i in range(512): # we have 512 features in our last conv layer\n",
        "    for i in range(conv_ouput_values.shape[2]): # daniel\n",
        "        conv_ouput_values[:,:,i] *= grads_values[i]\n",
        "    \n",
        "    # create a heatmap\n",
        "    heatmap = np.mean(conv_ouput_values, axis=-1)\n",
        "    \n",
        "    # remove negative values\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    \n",
        "    # normalize\n",
        "    heatmap /= heatmap.max()\n",
        "    \n",
        "    return heatmap"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0"
      ],
      "metadata": {
        "id": "zeXWpNlapUFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX1madjMm_oO"
      },
      "outputs": [],
      "source": [
        "# select the sample and read the corresponding image and label\n",
        "sample_image = cv2.imread(valid_df.iloc[idx]['image'])\n",
        "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n",
        "sample_label = valid_df.iloc[idx][\"label\"]\n",
        "\n",
        "# pre-process the image\n",
        "sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
        "sample_image_processed = preprocess_input(sample_image_processed)\n",
        "\n",
        "# get the label predicted by our original model\n",
        "pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n",
        "\n",
        "# get the heatmap for class activation map(CAM)\n",
        "heatmap = get_CAM(sample_image_processed, pred_label)\n",
        "heatmap = cv2.resize(heatmap, (sample_image.shape[0], sample_image.shape[1]))\n",
        "heatmap = heatmap *255\n",
        "heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "super_imposed_image = heatmap * 0.5 + sample_image\n",
        "super_imposed_image = np.clip(super_imposed_image, 0,255).astype(np.uint8)\n",
        "\n",
        "# Ploting\n",
        "fontsize = 10\n",
        "fig, axes = plt.subplots( 1, 3, figsize=( 8, 8 ) )\n",
        "axes[0].set_title( f'True label: {sample_label} \\n Predicted label: {pred_label}',\n",
        "                  fontsize = fontsize )\n",
        "axes[0].axis('off')\n",
        "axes[0].imshow( sample_image )\n",
        "\n",
        "axes[1].set_title( f'Class Activation Map',\n",
        "                  fontsize = fontsize )\n",
        "axes[1].axis('off')\n",
        "axes[1].imshow( heatmap )\n",
        "\n",
        "axes[2].set_title( f'Activation Map Superimposed',\n",
        "                  fontsize = fontsize )\n",
        "axes[2].axis('off')\n",
        "axes[2].imshow( super_imposed_image )\n",
        "plt.show()\n",
        "\n",
        "# # Plot just CAM of the layer\n",
        "# plt.figure( figsize=(2, 2) )\n",
        "# plt.title( f'Class Activation Map - Layer: {layer}' )\n",
        "# plt.imshow( heatmap )\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}