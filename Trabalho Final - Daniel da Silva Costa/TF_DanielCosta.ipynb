{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Based on \n",
        "\n",
        "Convolutional Neural Network (CNN)\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/cnn\n",
        "\n",
        "What does a CNN see?\n",
        "\n",
        "https://www.kaggle.com/code/aakashnain/what-does-a-cnn-see/notebook\n",
        "\n",
        "Grad-CAM class activation visualization\n",
        "\n",
        "https://keras.io/examples/vision/grad_cam/"
      ],
      "metadata": {
        "id": "GxV89Mg4jsE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efmQQxs0g7El",
        "outputId": "764273b0-e793-45bb-d1c0-b33710c5f7ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.2] [PUC-Rio] Visão Computacional - Professor: Marcelo Gattass/Trabalhos/Trabalho Final/Code/What does a CNN see?/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2srSkZGLg7PA",
        "outputId": "5c3d9e1d-5340-4693-b60f-6b6b50deb9f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.2] [PUC-Rio] Visão Computacional - Professor: Marcelo Gattass/Trabalhos/Trabalho Final/Code/What does a CNN see?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8peNVoSg7RY",
        "outputId": "99b10706-ac69-4366-8c5d-2a00ec746ee0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.2] [PUC-Rio] Visão Computacional - Professor: Marcelo Gattass/Trabalhos/Trabalho Final/Code/What does a CNN see?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = './data/'"
      ],
      "metadata": {
        "id": "RJyl7C3Qg7T5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_cd_jZ2kaoHo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "from pathlib import Path\n",
        "import imgaug as aug\n",
        "import imgaug.augmenters as iaa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "\n",
        "tf.compat.v1.disable_eager_execution() # daniel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for hash based operations in python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "seed=1234\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "# tf.set_random_seed(seed) # obsolete\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# Make the augmentation sequence deterministic\n",
        "aug.seed(seed)"
      ],
      "metadata": {
        "id": "5jqnf4j8yprF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As usual, define some paths first to make life simpler\n",
        "training_data = Path(data_folder + '/training/') \n",
        "validation_data = Path(data_folder + '/validation/') \n",
        "labels_path = Path(data_folder + '/monkey_labels.txt')"
      ],
      "metadata": {
        "id": "MvwvRZmRg7WX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_info = []\n",
        "\n",
        "# Read the file\n",
        "lines = labels_path.read_text().strip().splitlines()[1:]\n",
        "for line in lines:\n",
        "    line = line.split(',')\n",
        "    line = [x.strip(' \\n\\t\\r') for x in line]\n",
        "    line[3], line[4] = int(line[3]), int(line[4])\n",
        "    line = tuple(line)\n",
        "    labels_info.append(line)\n",
        "    \n",
        "# Convert the data into a pandas dataframe\n",
        "labels_info = pd.DataFrame(labels_info, columns=['Label', 'Latin Name', 'Common Name', \n",
        "                                                 'Train Images', 'Validation Images'], index=None)\n",
        "# Sneak peek \n",
        "labels_info.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WHnCSO4Yg7YY",
        "outputId": "881c9492-ee56-4d77-c86e-a22f40aaa044"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Label             Latin Name                Common Name  Train Images  \\\n",
              "0    n0      alouatta_palliata             mantled_howler           131   \n",
              "1    n1     erythrocebus_patas               patas_monkey           139   \n",
              "2    n2         cacajao_calvus                bald_uakari           137   \n",
              "3    n3         macaca_fuscata           japanese_macaque           152   \n",
              "4    n4        cebuella_pygmea             pygmy_marmoset           131   \n",
              "5    n5        cebus_capucinus      white_headed_capuchin           141   \n",
              "6    n6        mico_argentatus           silvery_marmoset           132   \n",
              "7    n7       saimiri_sciureus     common_squirrel_monkey           142   \n",
              "8    n8        aotus_nigriceps  black_headed_night_monkey           133   \n",
              "9    n9  trachypithecus_johnii             nilgiri_langur           132   \n",
              "\n",
              "   Validation Images  \n",
              "0                 26  \n",
              "1                 28  \n",
              "2                 27  \n",
              "3                 30  \n",
              "4                 26  \n",
              "5                 28  \n",
              "6                 26  \n",
              "7                 28  \n",
              "8                 27  \n",
              "9                 26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0f71861-dda8-4d92-87fa-4b3a16fca6f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Latin Name</th>\n",
              "      <th>Common Name</th>\n",
              "      <th>Train Images</th>\n",
              "      <th>Validation Images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n0</td>\n",
              "      <td>alouatta_palliata</td>\n",
              "      <td>mantled_howler</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n1</td>\n",
              "      <td>erythrocebus_patas</td>\n",
              "      <td>patas_monkey</td>\n",
              "      <td>139</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>n2</td>\n",
              "      <td>cacajao_calvus</td>\n",
              "      <td>bald_uakari</td>\n",
              "      <td>137</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>n3</td>\n",
              "      <td>macaca_fuscata</td>\n",
              "      <td>japanese_macaque</td>\n",
              "      <td>152</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>n4</td>\n",
              "      <td>cebuella_pygmea</td>\n",
              "      <td>pygmy_marmoset</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>n5</td>\n",
              "      <td>cebus_capucinus</td>\n",
              "      <td>white_headed_capuchin</td>\n",
              "      <td>141</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>n6</td>\n",
              "      <td>mico_argentatus</td>\n",
              "      <td>silvery_marmoset</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>n7</td>\n",
              "      <td>saimiri_sciureus</td>\n",
              "      <td>common_squirrel_monkey</td>\n",
              "      <td>142</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>n8</td>\n",
              "      <td>aotus_nigriceps</td>\n",
              "      <td>black_headed_night_monkey</td>\n",
              "      <td>133</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>n9</td>\n",
              "      <td>trachypithecus_johnii</td>\n",
              "      <td>nilgiri_langur</td>\n",
              "      <td>132</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0f71861-dda8-4d92-87fa-4b3a16fca6f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d0f71861-dda8-4d92-87fa-4b3a16fca6f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d0f71861-dda8-4d92-87fa-4b3a16fca6f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary to map the labels to integers\n",
        "labels_dict= {'n0':0, 'n1':1, 'n2':2, 'n3':3, 'n4':4, 'n5':5, 'n6':6, 'n7':7, 'n8':8, 'n9':9}\n",
        "\n",
        "# map labels to common names\n",
        "names_dict = dict(zip(labels_dict.values(), labels_info[\"Common Name\"]))\n",
        "print(names_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkdkK-hRg7a6",
        "outputId": "13decbff-9070-4efa-840b-f505409933fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'mantled_howler', 1: 'patas_monkey', 2: 'bald_uakari', 3: 'japanese_macaque', 4: 'pygmy_marmoset', 5: 'white_headed_capuchin', 6: 'silvery_marmoset', 7: 'common_squirrel_monkey', 8: 'black_headed_night_monkey', 9: 'nilgiri_langur'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe for the training dataset\n",
        "train_df = []\n",
        "for folder in os.listdir(training_data):\n",
        "    # Define the path to the images\n",
        "    imgs_path = training_data / folder\n",
        "    \n",
        "    # Get the list of all the images stored in that directory\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    \n",
        "    # Store each image path and corresponding label \n",
        "    for img_name in imgs:\n",
        "        train_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "\n",
        "train_df = pd.DataFrame(train_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "train_df = train_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# Creating dataframe for validation data in a similar fashion\n",
        "valid_df = []\n",
        "for folder in os.listdir(validation_data):\n",
        "    imgs_path = validation_data / folder\n",
        "    imgs = sorted(imgs_path.glob('*.jpg'))\n",
        "    for img_name in imgs:\n",
        "        valid_df.append((str(img_name), labels_dict[folder]))\n",
        "\n",
        "        \n",
        "valid_df = pd.DataFrame(valid_df, columns=['image', 'label'], index=None)\n",
        "# shuffle the dataset \n",
        "valid_df = valid_df.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# How many samples do we have in our training and validation data?\n",
        "print(\"Number of traininng samples: \", len(train_df))\n",
        "print(\"Number of validation samples: \", len(valid_df))\n",
        "\n",
        "# sneak peek of the training and validation dataframes\n",
        "print(\"\\n\",train_df.head(), \"\\n\")\n",
        "print(\"=================================================================\\n\")\n",
        "print(\"\\n\", valid_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i6qJizQhpdo",
        "outputId": "f6ba7092-69cf-45e0-8c86-e7ae87ea8b2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of traininng samples:  1096\n",
            "Number of validation samples:  272\n",
            "\n",
            "                         image  label\n",
            "0  data/training/n2/n2117.jpg      2\n",
            "1  data/training/n7/n7028.jpg      7\n",
            "2  data/training/n0/n0155.jpg      0\n",
            "3  data/training/n7/n7064.jpg      7\n",
            "4  data/training/n2/n2133.jpg      2 \n",
            "\n",
            "=================================================================\n",
            "\n",
            "\n",
            "                           image  label\n",
            "0   data/validation/n7/n718.jpg      7\n",
            "1  data/validation/n6/n6013.jpg      6\n",
            "2  data/validation/n7/n7012.jpg      7\n",
            "3   data/validation/n5/n512.jpg      5\n",
            "4   data/validation/n5/n509.jpg      5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some constants(not truly though!) \n",
        "\n",
        "# dimensions to consider for the images\n",
        "img_rows, img_cols, img_channels = 224,224,3\n",
        "\n",
        "# batch size for training  \n",
        "batch_size=8\n",
        "\n",
        "# total number of classes in the dataset\n",
        "nb_classes=10"
      ],
      "metadata": {
        "id": "-zT0naayhpgL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation sequence \n",
        "seq = iaa.OneOf([\n",
        "    iaa.Fliplr(), # horizontal flips\n",
        "    iaa.Affine(rotate=20), # roatation\n",
        "    iaa.Multiply((1.2, 1.5))]) #random brightness"
      ],
      "metadata": {
        "id": "JETuHE8Dhpih"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(data, batch_size, is_validation_data=False):\n",
        "    # Get total number of samples in the data\n",
        "    n = len(data)\n",
        "    nb_batches = int(np.ceil(n/batch_size))\n",
        "\n",
        "    # Get a numpy array of all the indices of the input data\n",
        "    indices = np.arange(n)\n",
        "    \n",
        "    # Define two numpy arrays for containing batch data and labels\n",
        "    batch_data = np.zeros((batch_size, img_rows, img_cols, img_channels), dtype=np.float32)\n",
        "    batch_labels = np.zeros((batch_size, nb_classes), dtype=np.float32)\n",
        "    \n",
        "    while True:\n",
        "        if not is_validation_data:\n",
        "            # shuffle indices for the training data\n",
        "            np.random.shuffle(indices)\n",
        "            \n",
        "        for i in range(nb_batches):\n",
        "            # get the next batch \n",
        "            next_batch_indices = indices[i*batch_size:(i+1)*batch_size]\n",
        "            \n",
        "            # process the next batch\n",
        "            for j, idx in enumerate(next_batch_indices):\n",
        "                img = cv2.imread(data.iloc[idx][\"image\"])\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                label = data.iloc[idx][\"label\"]\n",
        "                \n",
        "                if not is_validation_data:\n",
        "                    img = seq.augment_image(img)\n",
        "                \n",
        "                img = cv2.resize(img, (img_rows, img_cols)).astype(np.float32)\n",
        "                batch_data[j] = img\n",
        "                batch_labels[j] = to_categorical(label,num_classes=nb_classes)\n",
        "            \n",
        "            # batch_data = preprocess_input(batch_data) # daniel\n",
        "            yield batch_data, batch_labels"
      ],
      "metadata": {
        "id": "tyF1H0Cih2KD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training data generator \n",
        "train_data_gen = data_generator(train_df, batch_size)\n",
        "\n",
        "# validation data generator \n",
        "valid_data_gen = data_generator(valid_df, batch_size, is_validation_data=True)"
      ],
      "metadata": {
        "id": "wxFNrRZJhpk2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# # Normalize pixel values to be between 0 and 1\n",
        "# train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "BX2clvaAa2ka"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "#                'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# plt.figure(figsize=(10,10))\n",
        "# for i in range(25):\n",
        "#     plt.subplot(5,5,i+1)\n",
        "#     plt.xticks([])\n",
        "#     plt.yticks([])\n",
        "#     plt.grid(False)\n",
        "#     plt.imshow(train_images[i])\n",
        "#     # The CIFAR labels happen to be arrays, \n",
        "#     # which is why you need the extra index\n",
        "#     plt.xlabel(class_names[train_labels[i][0]])\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "2vLfuAlxa2nQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "# # tf.keras.layers.Conv2D( filters, kernel_size, ...)\n",
        "\n",
        "# model = models.Sequential()\n",
        "\n",
        "# model.add(layers.Conv2D(32, (2, 2), activation='relu', input_shape=(32, 32, 3), padding='same'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Conv2D(64, (2, 2), activation='relu', padding='same'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "# model.add(layers.Conv2D(128, (2, 2), activation='relu', padding='same'))\n",
        "# model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# model.add(layers.Flatten())\n",
        "# model.add(layers.Dense(512, activation='relu'))\n",
        "# model.add(layers.Dense(10))\n",
        "\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "W-bIIim7a2r1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
        "# tf.keras.layers.Conv2D( filters, kernel_size, ...)\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add( layers.InputLayer(input_shape=(224, 224, 3)) )\n",
        "model.add( layers.Conv2D(32, (2, 2), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(64, (2, 2), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(128, (2, 2), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Conv2D(256, (2, 2), \n",
        "                        padding='same',\n",
        "                        activation='relu') )\n",
        "model.add( layers.MaxPooling2D((2, 2)) )\n",
        "\n",
        "model.add( layers.Flatten() )\n",
        "model.add( layers.Dense(50176, activation='relu') )\n",
        "model.add( layers.Dense(10) )\n",
        "\n",
        "optimizer = RMSprop(0.001)\n",
        "model.compile(optimizer = optimizer, \n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_bwkVAF8Xux",
        "outputId": "7b116620-9e1b-4c7f-9185-e73ed9e97a87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 32)      416       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 64)      8256      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 256)       131328    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 50176)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50176)             2517681152\n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                501770    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,518,355,818\n",
            "Trainable params: 2,518,355,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# always user earlystopping\n",
        "# the restore_best_weights parameter load the weights of the best iteration once the training finishes\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "# checkpoint to save model\n",
        "chkpt = ModelCheckpoint(filepath=\"model1\", save_best_only=True)\n",
        "\n",
        "# number of training and validation steps for training and validation\n",
        "nb_train_steps = int(np.ceil(len(train_df)/batch_size))\n",
        "nb_valid_steps = int(np.ceil(len(valid_df)/batch_size))"
      ],
      "metadata": {
        "id": "l60DDFIUiru_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1"
      ],
      "metadata": {
        "id": "CGJpIcngoqU9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "history = model.fit(train_data_gen, \n",
        "                              epochs = epochs, \n",
        "                              steps_per_epoch = nb_train_steps, \n",
        "                              validation_data = valid_data_gen, \n",
        "                              validation_steps = nb_valid_steps,\n",
        "                              callbacks = [es,chkpt])"
      ],
      "metadata": {
        "id": "a0ZDXkOrnhvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "OPRm08iabMRJ",
        "outputId": "124f7087-ba4a-4e30-ad2c-78aa012907d7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2999879690b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's plot the loss and accuracy \n",
        "\n",
        "# get the training and validation accuracy from the history object\n",
        "train_acc = history.history['accuracy']\n",
        "valid_acc = history.history['val_accuracy']\n",
        "\n",
        "# get the loss\n",
        "train_loss = history.history['loss']\n",
        "valid_loss = history.history['val_loss']\n",
        "\n",
        "# get the number of entries\n",
        "xvalues = np.arange(len(train_acc))\n",
        "\n",
        "# visualize\n",
        "f,ax = plt.subplots(1,2, figsize=(10,5))\n",
        "ax[0].plot(xvalues, train_loss)\n",
        "ax[0].plot(xvalues, valid_loss)\n",
        "ax[0].set_title(\"Loss curve\")\n",
        "ax[0].set_xlabel(\"Epoch\")\n",
        "ax[0].set_ylabel(\"loss\")\n",
        "ax[0].legend(['train', 'validation'])\n",
        "\n",
        "ax[1].plot(xvalues, train_acc)\n",
        "ax[1].plot(xvalues, valid_acc)\n",
        "ax[1].set_title(\"Accuracy\")\n",
        "ax[1].set_xlabel(\"Epoch\")\n",
        "ax[1].set_ylabel(\"accuracy\")\n",
        "ax[1].legend(['train', 'validation'])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i-TfMsZmbMPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the final loss and accuracy on our validation data?\n",
        "valid_loss, valid_acc = model.evaluate_generator(valid_data_gen, steps=nb_valid_steps)\n",
        "print(f\"Final validation accuracy: {valid_acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "igHApboQi8O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select all the layers for which you want to visualize the outputs and store it in a list\n",
        "outputs = [layer.output for layer in model.layers[0:-3]]\n",
        "\n",
        "# Define a new model that generates the above output\n",
        "vis_model = Model(model.input, outputs)\n",
        "\n",
        "# check if we have all the layers we require for visualization \n",
        "vis_model.summary()"
      ],
      "metadata": {
        "id": "frDc73uXdnZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vis_model.predict( test_images )"
      ],
      "metadata": {
        "id": "w9VyITd_dnby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# outputs[-1].name"
      ],
      "metadata": {
        "id": "-ourPRBReVfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# store the layer names we are interested in\n",
        "layer_names = []\n",
        "for layer in outputs:\n",
        "    layer_names.append(layer.name.split(\"/\")[0])\n",
        "\n",
        "    \n",
        "print(\"Layers going to be used for visualization: \")\n",
        "print(layer_names)"
      ],
      "metadata": {
        "id": "6LttILiKdneK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_rows = train_images[16].shape[0]\n",
        "# img_rows"
      ],
      "metadata": {
        "id": "0X7odh5XdT_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_cols = train_images[16].shape[1]\n",
        "# img_cols"
      ],
      "metadata": {
        "id": "o0xEykqfdVNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img_channels = train_images[16].shape[2]\n",
        "# img_channels"
      ],
      "metadata": {
        "id": "iDt8HdPWdWPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_images[16]"
      ],
      "metadata": {
        "id": "Ko1RnVBYhBr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_labels[16][0]"
      ],
      "metadata": {
        "id": "70lfB8MqhD5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.predict(test_images)"
      ],
      "metadata": {
        "id": "tbH-QFUBvEpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_labels = model.predict(test_images)\n",
        "# pred_labels"
      ],
      "metadata": {
        "id": "YJ8-FExhzyEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_labels[0]"
      ],
      "metadata": {
        "id": "diT0SYnG0LM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_label = np.argmax(pred_labels[0], axis=-1)\n",
        "# pred_label"
      ],
      "metadata": {
        "id": "2pfYn-N_u7p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model1 = Model(model.input, model.outputs)\n",
        "# model1.summary()"
      ],
      "metadata": {
        "id": "DR3Duw6oxoUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_images[16].shape"
      ],
      "metadata": {
        "id": "um8XbJap0xia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_image_processed = np.expand_dims(test_images[16], axis=0)\n",
        "# sample_image_processed.shape"
      ],
      "metadata": {
        "id": "pCODrBxI0w6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_labels_0 = model.predict(sample_image_processed)\n",
        "# pred_labels_0"
      ],
      "metadata": {
        "id": "Nd4Xo-LHwoq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pred_label_0 = np.argmax(pred_labels_0, axis=-1)[0]\n",
        "# pred_label_0"
      ],
      "metadata": {
        "id": "NsxonfBu1H0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_labels[16][0]"
      ],
      "metadata": {
        "id": "JRxeAAPc2Ry3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_names[pred_label_0]"
      ],
      "metadata": {
        "id": "jGUCpblw1cfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_names[test_labels[16][0]]"
      ],
      "metadata": {
        "id": "6a5P0Zzh1hsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 0"
      ],
      "metadata": {
        "id": "j25cnW73nOn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select the sample and read the corresponding image and label\n",
        "sample_image = cv2.imread(valid_df.iloc[idx]['image'])\n",
        "sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "sample_image = cv2.resize(sample_image, (img_rows, img_cols))\n",
        "sample_label = valid_df.iloc[idx][\"label\"]\n",
        "\n",
        "# pre-process the image\n",
        "sample_image_processed = np.expand_dims(sample_image, axis=0)\n",
        "# sample_image_processed = preprocess_input(sample_image_processed)"
      ],
      "metadata": {
        "id": "CeuJZS8rnK3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the label predicted by our original model\n",
        "pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n",
        "pred_label"
      ],
      "metadata": {
        "id": "K-ESlRGfnWgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_CAM(image, predicted_label, model, layer_name):\n",
        "\n",
        "    # choose the last conv layer in your model\n",
        "    conv_layer = model.get_layer( layer_name )\n",
        "\n",
        "    # https://keras.io/examples/vision/grad_cam/\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], \n",
        "        [conv_layer.output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_layer_output, preds = grad_model(image)\n",
        "        class_channel = preds[:, tf.argmax(preds[0])]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    conv_layer_output = conv_layer_output[0]\n",
        "    heatmap = conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "    # # https://www.kaggle.com/code/aakashnain/what-does-a-cnn-see/notebook\n",
        "    # # we want the activations for the predicted label\n",
        "    # predicted_output = model.output[:, predicted_label]\n",
        "    \n",
        "    # # get the gradients wrt to the last conv layer\n",
        "    # grads = K.gradients(predicted_output, conv_layer.output)[0]\n",
        "    \n",
        "    # # take mean gradient per feature map\n",
        "    # grads = K.mean(grads, axis=(0,1,2)) # GAP - Global Average Pooling\n",
        "    \n",
        "    # # Define a function that generates the values for the output and gradients\n",
        "    # evaluation_function = K.function([model.input], [grads, conv_layer.output[0]])\n",
        "    \n",
        "    # # get the values\n",
        "    # grads_values, conv_ouput_values = evaluation_function([image])\n",
        "    \n",
        "    # # CAM - Class Activation Map\n",
        "    # # iterate over each feature map in yout conv output and multiply\n",
        "    # # the gradient values with the conv output values. This gives an \n",
        "    # # indication of \"how important a feature is\"\n",
        "    # # for i in range(512): # we have 512 features in our last conv layer\n",
        "    # for i in range(256): # we have 512 features in our last conv layer\n",
        "    #     conv_ouput_values[:,:,i] *= grads_values[i]\n",
        "    \n",
        "    # # create a heatmap\n",
        "    # heatmap = np.mean(conv_ouput_values, axis=-1)\n",
        "    \n",
        "    # # remove negative values\n",
        "    # heatmap = np.maximum(heatmap, 0)\n",
        "    \n",
        "    # # normalize\n",
        "    # heatmap /= heatmap.max()\n",
        "    \n",
        "    # return heatmap"
      ],
      "metadata": {
        "id": "vhhUyYNOe9FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_CAM(image, predicted_label, model, layer_name)\n",
        "get_CAM(\n",
        "    sample_image_processed, \n",
        "    pred_label, \n",
        "    model, \n",
        "    layer_names[-1])"
      ],
      "metadata": {
        "id": "yXXg0VJpe9Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # get the heatmap for class activation map(CAM)\n",
        "# heatmap = get_CAM(sample_image_processed, \n",
        "#                   pred_label_0, \n",
        "#                   model, \n",
        "#                   layer_names[-1])\n",
        "# heatmap = cv2.resize(heatmap, (test_images[16].shape[0], test_images[16].shape[1]))\n",
        "# heatmap = heatmap *255\n",
        "# heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
        "# heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "# super_imposed_image = heatmap * 0.5 + test_images[16]\n",
        "# super_imposed_image = np.clip(super_imposed_image, 0,255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "iRiZIKF8a2xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# f,ax = plt.subplots(2,2, figsize=(15,8))\n",
        "# ax[0,0].imshow(test_images[16])\n",
        "# ax[0,0].set_title(f\"True label: {class_names[test_labels[16][0]]} \\n Predicted label: {class_names[pred_label_0]}\")\n",
        "# ax[0,0].axis('off')\n",
        "\n",
        "# ax[0,1].imshow(heatmap)\n",
        "# ax[0,1].set_title(\"Class Activation Map\")\n",
        "# ax[0,1].axis('off')\n",
        "\n",
        "# ax[1,0].imshow(super_imposed_image)\n",
        "# ax[1,0].set_title(\"Activation map superimposed\")\n",
        "# ax[1,0].axis('off')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "ldGWuGixuAQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_layer(layer):\n",
        "  \n",
        "  # get the heatmap for class activation map(CAM)\n",
        "  heatmap = get_CAM(sample_image_processed, \n",
        "                    pred_label_0, \n",
        "                    model, \n",
        "                    layer)\n",
        "  heatmap = cv2.resize(\n",
        "      heatmap, \n",
        "      (test_images[16].shape[0], test_images[16].shape[1]))\n",
        "  heatmap = heatmap *255\n",
        "  heatmap = np.clip(heatmap, 0, 255).astype(np.uint8)\n",
        "  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "  super_imposed_image = heatmap * 0.5 + test_images[16]\n",
        "  super_imposed_image = np.clip(super_imposed_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "  # Ploting\n",
        "  fig, axes = plt.subplots( 1, 3, figsize=( 30, 10 ) )\n",
        "  axes[0].set_title( f'True label: {class_names[test_labels[16][0]]} \\n Predicted label: {class_names[pred_label_0]}' )\n",
        "  axes[0].axis('off')\n",
        "  axes[0].imshow( test_images[16] )\n",
        "  axes[1].set_title( f'Class Activation Map - Layer: {layer}' )\n",
        "  axes[1].axis('off')\n",
        "  axes[1].imshow( heatmap )\n",
        "  axes[2].set_title( f'Activation Map Superimposed - Layer: {layer}' )\n",
        "  axes[2].axis('off')\n",
        "  axes[2].imshow( super_imposed_image )\n",
        "  plt.show()\n",
        "\n",
        "  # # Plot just CAM of the layer\n",
        "  # plt.figure( figsize=(2, 2) )\n",
        "  # plt.title( f'Class Activation Map - Layer: {layer}' )\n",
        "  # plt.imshow( heatmap )\n",
        "  # plt.show()\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "id": "I2vYf16nuAU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layer_names_reversed = layer_names[::-1] #reversing using list slicing\n",
        "# for layer in layer_names_reversed:\n",
        "for layer in layer_names:\n",
        "\n",
        "  if 'pooling' not in layer:\n",
        "    visualize_layer(layer)"
      ],
      "metadata": {
        "id": "us5yVWMtmRTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for index, test_img in enumerate( test_images ):\n",
        "\n",
        "#   if index > 20:\n",
        "#     break\n",
        "  \n",
        "#   # Plot just CAM of the layer\n",
        "#   plt.figure( figsize=(1, 1) )\n",
        "#   plt.title( f'index: {index}' )\n",
        "#   plt.imshow( test_img )\n",
        "#   plt.show()"
      ],
      "metadata": {
        "id": "sOMnQJBcmRX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2XbswWOwraeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iR6KDB15rag1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4M4Iscndrajt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}